{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor Flow Version: 2.3.2\n",
      "Keras Version: 2.4.0\n",
      "\n",
      "Python 3.8.8 | packaged by conda-forge | (default, Feb 20 2021, 16:22:27) \n",
      "[GCC 9.3.0]\n",
      "GPU is NOT AVAILABLE\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "# Before using tensorflow:\n",
    "import os\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as KB\n",
    "from matplotlib import pylab as plt\n",
    "import tensorflow.keras\n",
    "#from tensorflow.python.framework.ops import disable_eager_execution\n",
    "#disable_eager_execution()\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "print(f\"Tensor Flow Version: {tf.__version__}\")\n",
    "print(f\"Keras Version: {tensorflow.keras.__version__}\")\n",
    "print()\n",
    "print(f\"Python {sys.version}\")\n",
    "\n",
    "gpu = len(tf.config.list_physical_devices('GPU'))>0\n",
    "print(\"GPU is\", \"available\" if gpu else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the model / CNN architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from client.models.AMLmodel import construct_model\n",
    "model = construct_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 100, 100, 32)      1184      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 100, 100, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 98, 98, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 98, 98, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 49, 49, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 49, 49, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 49, 49, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 49, 49, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 47, 47, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 47, 47, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 23, 23, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 23, 23, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 33856)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               17334784  \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 15)                7695      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 15)                0         \n",
      "=================================================================\n",
      "Total params: 17,410,383\n",
      "Trainable params: 17,409,359\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use training data from one clinic to train a model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from client.data.datagenerator import DataGenerator\n",
    "\n",
    "labels0 = np.load('dataset/processed/data_partitions/partition0/labels.npy', allow_pickle=True).item()\n",
    "data_path0 = 'dataset/processed/data_partitions/partition0/data_singlets'\n",
    "\n",
    "ids0 = [l for l in labels0]\n",
    "np.random.shuffle(ids0)\n",
    "train_split_index = int(len(ids0)*0.9)\n",
    "train_ids = ids0[:train_split_index]\n",
    "val_ids = ids0[train_split_index:]\n",
    "\n",
    "train_gen = DataGenerator(train_ids,labels0, data_path0, dim=(100,100), batch_size=32)\n",
    "val_gen = DataGenerator(val_ids,labels0, data_path0, dim=(100,100), batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "17/17 [==============================] - 12s 715ms/step - loss: 1.9728 - accuracy: 0.4393\n",
      "Epoch 2/20\n",
      "17/17 [==============================] - 12s 707ms/step - loss: 1.2845 - accuracy: 0.6746\n",
      "Epoch 3/20\n",
      "17/17 [==============================] - 12s 697ms/step - loss: 0.9901 - accuracy: 0.7096\n",
      "Epoch 4/20\n",
      "17/17 [==============================] - 12s 697ms/step - loss: 0.8417 - accuracy: 0.7224\n",
      "Epoch 5/20\n",
      "17/17 [==============================] - 12s 697ms/step - loss: 0.5939 - accuracy: 0.8254\n",
      "Epoch 6/20\n",
      "17/17 [==============================] - 12s 701ms/step - loss: 0.4592 - accuracy: 0.8401\n",
      "Epoch 7/20\n",
      "17/17 [==============================] - 12s 702ms/step - loss: 0.3362 - accuracy: 0.8695\n",
      "Epoch 8/20\n",
      "17/17 [==============================] - 12s 692ms/step - loss: 0.2665 - accuracy: 0.9099\n",
      "Epoch 9/20\n",
      "17/17 [==============================] - 12s 685ms/step - loss: 0.2073 - accuracy: 0.9393\n",
      "Epoch 10/20\n",
      "17/17 [==============================] - 12s 686ms/step - loss: 0.1534 - accuracy: 0.9540\n",
      "Epoch 11/20\n",
      "17/17 [==============================] - 12s 694ms/step - loss: 0.1080 - accuracy: 0.9706\n",
      "Epoch 12/20\n",
      "17/17 [==============================] - 12s 678ms/step - loss: 0.1300 - accuracy: 0.9540\n",
      "Epoch 13/20\n",
      "17/17 [==============================] - 12s 708ms/step - loss: 0.0829 - accuracy: 0.9798\n",
      "Epoch 14/20\n",
      "17/17 [==============================] - 12s 695ms/step - loss: 0.0576 - accuracy: 0.9908\n",
      "Epoch 15/20\n",
      "17/17 [==============================] - 12s 715ms/step - loss: 0.0440 - accuracy: 0.9890\n",
      "Epoch 16/20\n",
      "17/17 [==============================] - 12s 688ms/step - loss: 0.0365 - accuracy: 0.9890\n",
      "Epoch 17/20\n",
      "17/17 [==============================] - 12s 685ms/step - loss: 0.0245 - accuracy: 0.9982\n",
      "Epoch 18/20\n",
      "17/17 [==============================] - 12s 697ms/step - loss: 0.0425 - accuracy: 0.9853\n",
      "Epoch 19/20\n",
      "17/17 [==============================] - 12s 691ms/step - loss: 0.0131 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "17/17 [==============================] - 12s 689ms/step - loss: 0.0252 - accuracy: 0.9963\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd04455c430>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_gen,epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model validation - plot a confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We reserve partition1 as a validation set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sort([k for k in labels0])\n",
    "\n",
    "labels1 = np.load('dataset/processed/data_partitions/partition1/labels.npy', allow_pickle=True).item()\n",
    "data_path1 = 'dataset/processed/data_partitions/partition1/data_singlets'\n",
    "\n",
    "ids1 = [l for l in labels1]\n",
    "np.random.shuffle(ids1)\n",
    "\n",
    "test_gen = DataGenerator(ids1,labels1, data_path1, dim=(100,100), batch_size=32)\n",
    "labels, preds = test_gen.predict_all(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(model, data_gen):\n",
    "    \n",
    "    labels, preds = data_gen.predict_all(model)\n",
    "\n",
    "    y_pred = np.argmax(preds,1)\n",
    "    y_data = np.argmax(labels,1)\n",
    "    M = np.zeros((16,16))\n",
    "\n",
    "    for pred_, true_ in zip(y_pred,y_data):\n",
    "        M[true_,pred_] +=1\n",
    "    \n",
    "    M[15,:15] = np.sum(M[:15,:15],0)\n",
    "    M[:15,15] = np.sum(M[:15,:15],1)\n",
    "    M[15,15] = np.sum(M[:15,:15])\n",
    "        \n",
    "    return M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "from client.models.AMLmodel import classes as aml_classes\n",
    "\n",
    "class_names_y = [aml_classes[k] for k in aml_classes] + ['Total']\n",
    "class_names_x = [k for k in aml_classes] + ['Total']\n",
    "\n",
    "def plot_confusion_matrix(matrix, title='Confusion matrix', cmap=plt.cm.autumn):\n",
    "    \n",
    "    f, ax = plt.subplots(1,1,figsize=(20,14))\n",
    "    color_mat = np.zeros(matrix.shape)\n",
    "    color_mat[:15,:15] = matrix[:15,:15]/np.maximum(1,np.sum(matrix[:15,:15],0))\n",
    "    ax.matshow(color_mat, cmap=cmap, norm=matplotlib.colors.LogNorm()) \n",
    "\n",
    "    tick_mark = np.arange(16)\n",
    "    ax.set_xticks(tick_mark)\n",
    "    ax.set_yticks(tick_mark)\n",
    "    ax.set_xticklabels(class_names_x)\n",
    "    ax.set_yticklabels(class_names_y)\n",
    "    \n",
    "    for (i, j), z in np.ndenumerate(matrix):\n",
    "        ax.text(j, i, '{:0.0f}'.format(z), ha='center', va='center')\n",
    "\n",
    "    ax.axvline(x=14.5,color='black',lw=5)\n",
    "    ax.axhline(y=14.5,color='black', lw=5)\n",
    "    ax.set_xlabel('Predicted class', fontsize=20)\n",
    "    ax.set_ylabel('True class', fontsize=20)\n",
    "\n",
    "M = confusion_matrix(model, test_gen)\n",
    "plot_confusion_matrix(M)\n",
    "plt.savefig('confusion_sample.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a model object in STACKn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.8/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10/12/2021 07:35:15 PM [deprecation.py:317] From /opt/conda/lib/python3.8/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.8/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10/12/2021 07:35:15 PM [deprecation.py:317] From /opt/conda/lib/python3.8/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/clinic1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10/12/2021 07:35:18 PM [builder_impl.py:774] Assets written to: models/clinic1/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to create model.\n",
      "Returned status code: 403\n",
      "Reason: Forbidden\n",
      "{\"detail\":\"Authentication credentials were not provided.\"}\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'repo' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-ce3c36a4c477>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mstackn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstackn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaved_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'models/clinic1/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mstackn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'aml-clinic1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrelease_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"major\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/stackn/stackn.py\u001b[0m in \u001b[0;36mcreate_object\u001b[0;34m(model_name, studio_url, model_file, project_name, release_type, object_type, model_description, model_card, s3storage, is_file, secure_mode)\u001b[0m\n\u001b[1;32m    476\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_check_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_msg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Failed to create model.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m         \u001b[0;31m# Delete model object from storage.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 478\u001b[0;31m         \u001b[0mrepo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete_artifact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_uid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    479\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'repo' is not defined"
     ]
    }
   ],
   "source": [
    "from stackn import stackn\n",
    "tf.saved_model.save(model, 'models/clinic1/')\n",
    "stackn.create_object('aml-clinic1', release_type=\"major\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save weights for use as an initial model in FEDn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model_single_clinic.npz'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fedn.utils.kerashelper import KerasHelper\n",
    "helper = KerasHelper()\n",
    "weights = model.get_weights()\n",
    "helper.save_model(weights, \"model_single_clinic.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
